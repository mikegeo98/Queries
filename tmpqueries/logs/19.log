21/05/27 18:02:48 WARN Utils: Your hostname, mikeg-UX305UA resolves to a loopback address: 127.0.1.1; using 192.168.1.20 instead (on interface wlp2s0)
21/05/27 18:02:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/05/27 18:02:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/05/27 18:02:51 INFO SparkContext: Running Spark version 3.1.1
21/05/27 18:02:51 INFO ResourceUtils: ==============================================================
21/05/27 18:02:51 INFO ResourceUtils: No custom resources configured for spark.driver.
21/05/27 18:02:51 INFO ResourceUtils: ==============================================================
21/05/27 18:02:51 INFO SparkContext: Submitted application: Query1_DFAPI
21/05/27 18:02:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/05/27 18:02:51 INFO ResourceProfile: Limiting resource is cpu
21/05/27 18:02:51 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/05/27 18:02:51 INFO SecurityManager: Changing view acls to: mikeg
21/05/27 18:02:51 INFO SecurityManager: Changing modify acls to: mikeg
21/05/27 18:02:51 INFO SecurityManager: Changing view acls groups to: 
21/05/27 18:02:51 INFO SecurityManager: Changing modify acls groups to: 
21/05/27 18:02:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(mikeg); groups with view permissions: Set(); users  with modify permissions: Set(mikeg); groups with modify permissions: Set()
21/05/27 18:02:52 INFO Utils: Successfully started service 'sparkDriver' on port 35641.
21/05/27 18:02:52 INFO SparkEnv: Registering MapOutputTracker
21/05/27 18:02:52 INFO SparkEnv: Registering BlockManagerMaster
21/05/27 18:02:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/27 18:02:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/27 18:02:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/27 18:02:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5d395b03-feea-4ee6-a17f-e91f1634c3b7
21/05/27 18:02:52 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/05/27 18:02:52 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/27 18:02:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/05/27 18:02:53 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/05/27 18:02:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.20:4041
21/05/27 18:02:53 INFO Executor: Starting executor ID driver on host 192.168.1.20
21/05/27 18:02:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41791.
21/05/27 18:02:53 INFO NettyBlockTransferService: Server created on 192.168.1.20:41791
21/05/27 18:02:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/27 18:02:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.20, 41791, None)
21/05/27 18:02:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.20:41791 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.1.20, 41791, None)
21/05/27 18:02:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.20, 41791, None)
21/05/27 18:02:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.20, 41791, None)
21/05/27 18:02:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/mikeg/Documents/databases/TPC-H/TPC-H_Tools_v3.0.0/dbgen/tmpqueries/spark-warehouse/').
21/05/27 18:02:57 INFO SharedState: Warehouse path is 'file:/home/mikeg/Documents/databases/TPC-H/TPC-H_Tools_v3.0.0/dbgen/tmpqueries/spark-warehouse/'.
21/05/27 18:03:01 INFO InMemoryFileIndex: It took 83 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
21/05/27 18:03:03 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
21/05/27 18:03:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(l_shipinstruct),In(l_shipmode, [AIR,AIR REG]),EqualTo(l_shipinstruct,DELIVER IN PERSON),IsNotNull(l_partkey),Or(Or(And(GreaterThanOrEqual(l_quantity,1.0),LessThanOrEqual(l_quantity,11.0)),And(GreaterThanOrEqual(l_quantity,10.0),LessThanOrEqual(l_quantity,20.0))),And(GreaterThanOrEqual(l_quantity,20.0),LessThanOrEqual(l_quantity,30.0)))
21/05/27 18:03:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(l_shipinstruct#103),l_shipmode#104 IN (AIR,AIR REG),(l_shipinstruct#103 = DELIVER IN PERSON),isnotnull(l_partkey#91L),((((l_quantity#94 >= 1.0) AND (l_quantity#94 <= 11.0)) OR ((l_quantity#94 >= 10.0) AND (l_quantity#94 <= 20.0))) OR ((l_quantity#94 >= 20.0) AND (l_quantity#94 <= 30.0)))
21/05/27 18:03:05 INFO FileSourceStrategy: Output Data Schema: struct<l_partkey: bigint, l_quantity: double, l_extendedprice: double, l_discount: double, l_shipinstruct: string ... 1 more field>
21/05/27 18:03:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(p_size),GreaterThanOrEqual(p_size,1),IsNotNull(p_partkey),Or(Or(And(And(EqualTo(p_brand,Brand#12),In(p_container, [SM CASE,SM BOX,SM PACK,SM PKG])),LessThanOrEqual(p_size,5)),And(And(EqualTo(p_brand,Brand#23),In(p_container, [MED BAG,MED BOX,MED PKG,MED PACK])),LessThanOrEqual(p_size,10))),And(And(EqualTo(p_brand,Brand#34),In(p_container, [LG CASE,LG BOX,LG PACK,LG PKG])),LessThanOrEqual(p_size,15)))
21/05/27 18:03:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(p_size#19),(p_size#19 >= 1),isnotnull(p_partkey#14L),(((((p_brand#17 = Brand#12) AND p_container#20 IN (SM CASE,SM BOX,SM PACK,SM PKG)) AND (p_size#19 <= 5)) OR (((p_brand#17 = Brand#23) AND p_container#20 IN (MED BAG,MED BOX,MED PKG,MED PACK)) AND (p_size#19 <= 10))) OR (((p_brand#17 = Brand#34) AND p_container#20 IN (LG CASE,LG BOX,LG PACK,LG PKG)) AND (p_size#19 <= 15)))
21/05/27 18:03:05 INFO FileSourceStrategy: Output Data Schema: struct<p_partkey: bigint, p_brand: string, p_size: int, p_container: string ... 2 more fields>
21/05/27 18:03:06 INFO CodeGenerator: Code generated in 389.208817 ms
21/05/27 18:03:06 INFO CodeGenerator: Code generated in 389.961236 ms
21/05/27 18:03:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KiB, free 366.0 MiB)
21/05/27 18:03:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.0 MiB)
21/05/27 18:03:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.20:41791 (size: 24.0 KiB, free: 366.3 MiB)
21/05/27 18:03:06 INFO SparkContext: Created broadcast 0 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
21/05/27 18:03:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7082357 bytes, open cost is considered as scanning 4194304 bytes.
21/05/27 18:03:06 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
21/05/27 18:03:06 INFO DAGScheduler: Got job 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) with 4 output partitions
21/05/27 18:03:06 INFO DAGScheduler: Final stage: ResultStage 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266)
21/05/27 18:03:06 INFO DAGScheduler: Parents of final stage: List()
21/05/27 18:03:06 INFO DAGScheduler: Missing parents: List()
21/05/27 18:03:06 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266), which has no missing parents
21/05/27 18:03:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 22.0 KiB, free 366.0 MiB)
21/05/27 18:03:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.9 KiB, free 366.0 MiB)
21/05/27 18:03:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.20:41791 (size: 8.9 KiB, free: 366.3 MiB)
21/05/27 18:03:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383
21/05/27 18:03:06 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
21/05/27 18:03:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks resource profile 0
21/05/27 18:03:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.1.20, executor driver, partition 0, ANY, 4879 bytes) taskResourceAssignments Map()
21/05/27 18:03:06 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.1.20, executor driver, partition 1, ANY, 4879 bytes) taskResourceAssignments Map()
21/05/27 18:03:06 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.1.20, executor driver, partition 2, ANY, 4879 bytes) taskResourceAssignments Map()
21/05/27 18:03:06 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (192.168.1.20, executor driver, partition 3, ANY, 4879 bytes) taskResourceAssignments Map()
21/05/27 18:03:07 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/05/27 18:03:07 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/05/27 18:03:07 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/05/27 18:03:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/05/27 18:03:07 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/part.tbl, range: 14164714-21247071, partition values: [empty row]
21/05/27 18:03:07 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/part.tbl, range: 7082357-14164714, partition values: [empty row]
21/05/27 18:03:07 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/part.tbl, range: 21247071-24135125, partition values: [empty row]
21/05/27 18:03:07 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/part.tbl, range: 0-7082357, partition values: [empty row]
21/05/27 18:03:07 INFO CodeGenerator: Code generated in 19.829086 ms
21/05/27 18:03:07 INFO CodeGenerator: Code generated in 10.668412 ms
21/05/27 18:03:07 INFO CodeGenerator: Code generated in 12.054693 ms
21/05/27 18:03:07 INFO CodeGenerator: Code generated in 40.532239 ms
21/05/27 18:03:08 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2580 bytes result sent to driver
21/05/27 18:03:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 3853 bytes result sent to driver
21/05/27 18:03:08 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1524 ms on 192.168.1.20 (executor driver) (1/4)
21/05/27 18:03:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1575 ms on 192.168.1.20 (executor driver) (2/4)
21/05/27 18:03:08 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 4355 bytes result sent to driver
21/05/27 18:03:08 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1605 ms on 192.168.1.20 (executor driver) (3/4)
21/05/27 18:03:08 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 3968 bytes result sent to driver
21/05/27 18:03:08 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1624 ms on 192.168.1.20 (executor driver) (4/4)
21/05/27 18:03:08 INFO DAGScheduler: ResultStage 0 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:266) finished in 1.755 s
21/05/27 18:03:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/05/27 18:03:08 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/27 18:03:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/05/27 18:03:08 INFO DAGScheduler: Job 0 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266, took 1.827094 s
21/05/27 18:03:08 INFO CodeGenerator: Code generated in 11.084778 ms
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 1040.0 KiB, free 365.0 MiB)
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 364.9 MiB)
21/05/27 18:03:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.20:41791 (size: 13.4 KiB, free: 366.3 MiB)
21/05/27 18:03:08 INFO SparkContext: Created broadcast 2 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:266
21/05/27 18:03:08 INFO CodeGenerator: Code generated in 66.055022 ms
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 286.0 KiB, free 364.7 MiB)
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 364.6 MiB)
21/05/27 18:03:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.20:41791 (size: 24.0 KiB, free: 366.2 MiB)
21/05/27 18:03:08 INFO SparkContext: Created broadcast 3 from showString at NativeMethodAccessorImpl.java:0
21/05/27 18:03:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/05/27 18:03:08 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/05/27 18:03:08 INFO DAGScheduler: Registering RDD 7 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
21/05/27 18:03:08 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/05/27 18:03:08 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
21/05/27 18:03:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/05/27 18:03:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/05/27 18:03:08 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 35.8 KiB, free 364.6 MiB)
21/05/27 18:03:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 364.6 MiB)
21/05/27 18:03:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.20:41791 (size: 14.1 KiB, free: 366.2 MiB)
21/05/27 18:03:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1383
21/05/27 18:03:08 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
21/05/27 18:03:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 6 tasks resource profile 0
21/05/27 18:03:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4) (192.168.1.20, executor driver, partition 0, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:08 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5) (192.168.1.20, executor driver, partition 1, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:08 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6) (192.168.1.20, executor driver, partition 2, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:08 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7) (192.168.1.20, executor driver, partition 3, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
21/05/27 18:03:08 INFO Executor: Running task 1.0 in stage 1.0 (TID 5)
21/05/27 18:03:08 INFO Executor: Running task 2.0 in stage 1.0 (TID 6)
21/05/27 18:03:08 INFO Executor: Running task 3.0 in stage 1.0 (TID 7)
21/05/27 18:03:08 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 268435456-402653184, partition values: [empty row]
21/05/27 18:03:08 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 134217728-268435456, partition values: [empty row]
21/05/27 18:03:08 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 0-134217728, partition values: [empty row]
21/05/27 18:03:08 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 402653184-536870912, partition values: [empty row]
21/05/27 18:03:08 INFO CodeGenerator: Code generated in 16.390972 ms
21/05/27 18:03:09 INFO CodeGenerator: Code generated in 26.731987 ms
21/05/27 18:03:09 INFO CodeGenerator: Code generated in 13.17745 ms
21/05/27 18:03:09 INFO CodeGenerator: Code generated in 10.425782 ms
21/05/27 18:03:09 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.20:41791 in memory (size: 8.9 KiB, free: 366.2 MiB)
21/05/27 18:03:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 7). 2175 bytes result sent to driver
21/05/27 18:03:13 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 8) (192.168.1.20, executor driver, partition 4, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 4378 ms on 192.168.1.20 (executor driver) (1/6)
21/05/27 18:03:13 INFO Executor: Running task 4.0 in stage 1.0 (TID 8)
21/05/27 18:03:13 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 536870912-671088640, partition values: [empty row]
21/05/27 18:03:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 5). 2132 bytes result sent to driver
21/05/27 18:03:13 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 9) (192.168.1.20, executor driver, partition 5, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 18:03:13 INFO Executor: Running task 5.0 in stage 1.0 (TID 9)
21/05/27 18:03:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 4417 ms on 192.168.1.20 (executor driver) (2/6)
21/05/27 18:03:13 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 671088640-759863287, partition values: [empty row]
21/05/27 18:03:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 2132 bytes result sent to driver
21/05/27 18:03:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 4435 ms on 192.168.1.20 (executor driver) (3/6)
21/05/27 18:03:13 INFO Executor: Finished task 2.0 in stage 1.0 (TID 6). 2132 bytes result sent to driver
21/05/27 18:03:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 4448 ms on 192.168.1.20 (executor driver) (4/6)
21/05/27 18:03:15 INFO Executor: Finished task 5.0 in stage 1.0 (TID 9). 2132 bytes result sent to driver
21/05/27 18:03:15 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 9) in 1946 ms on 192.168.1.20 (executor driver) (5/6)
21/05/27 18:03:15 INFO Executor: Finished task 4.0 in stage 1.0 (TID 8). 2132 bytes result sent to driver
21/05/27 18:03:15 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 8) in 2641 ms on 192.168.1.20 (executor driver) (6/6)
21/05/27 18:03:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/27 18:03:15 INFO DAGScheduler: ShuffleMapStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 7.045 s
21/05/27 18:03:15 INFO DAGScheduler: looking for newly runnable stages
21/05/27 18:03:15 INFO DAGScheduler: running: Set()
21/05/27 18:03:15 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/05/27 18:03:15 INFO DAGScheduler: failed: Set()
21/05/27 18:03:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/27 18:03:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.2 KiB, free 364.6 MiB)
21/05/27 18:03:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 364.6 MiB)
21/05/27 18:03:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.20:41791 (size: 5.5 KiB, free: 366.2 MiB)
21/05/27 18:03:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1383
21/05/27 18:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/05/27 18:03:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
21/05/27 18:03:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10) (192.168.1.20, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/27 18:03:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
21/05/27 18:03:15 INFO ShuffleBlockFetcherIterator: Getting 6 (360.0 B) non-empty blocks including 6 (360.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/27 18:03:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/05/27 18:03:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2665 bytes result sent to driver
21/05/27 18:03:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 74 ms on 192.168.1.20 (executor driver) (1/1)
21/05/27 18:03:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/05/27 18:03:16 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.084 s
21/05/27 18:03:16 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/27 18:03:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/05/27 18:03:16 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 7.163691 s
21/05/27 18:03:16 INFO CodeGenerator: Code generated in 15.067541 ms
21/05/27 18:03:16 INFO SparkContext: Invoking stop() from shutdown hook
21/05/27 18:03:16 INFO SparkUI: Stopped Spark web UI at http://192.168.1.20:4041
21/05/27 18:03:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/27 18:03:16 INFO MemoryStore: MemoryStore cleared
21/05/27 18:03:16 INFO BlockManager: BlockManager stopped
21/05/27 18:03:16 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/27 18:03:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/27 18:03:16 INFO SparkContext: Successfully stopped SparkContext
21/05/27 18:03:16 INFO ShutdownHookManager: Shutdown hook called
21/05/27 18:03:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-daa98a08-2155-4e8c-9337-8d3f33095ea6/pyspark-bd2c4aa4-7304-4637-8b02-5599c7681412
21/05/27 18:03:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-8fecbdf3-6ce2-46b9-93bb-d32c9a6c335a
21/05/27 18:03:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-daa98a08-2155-4e8c-9337-8d3f33095ea6
