21/05/27 17:44:35 WARN Utils: Your hostname, mikeg-UX305UA resolves to a loopback address: 127.0.1.1; using 192.168.1.20 instead (on interface wlp2s0)
21/05/27 17:44:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
21/05/27 17:44:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/05/27 17:44:38 INFO SparkContext: Running Spark version 3.1.1
21/05/27 17:44:38 INFO ResourceUtils: ==============================================================
21/05/27 17:44:38 INFO ResourceUtils: No custom resources configured for spark.driver.
21/05/27 17:44:38 INFO ResourceUtils: ==============================================================
21/05/27 17:44:38 INFO SparkContext: Submitted application: Query1_DFAPI
21/05/27 17:44:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/05/27 17:44:38 INFO ResourceProfile: Limiting resource is cpu
21/05/27 17:44:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/05/27 17:44:38 INFO SecurityManager: Changing view acls to: mikeg
21/05/27 17:44:38 INFO SecurityManager: Changing modify acls to: mikeg
21/05/27 17:44:38 INFO SecurityManager: Changing view acls groups to: 
21/05/27 17:44:38 INFO SecurityManager: Changing modify acls groups to: 
21/05/27 17:44:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(mikeg); groups with view permissions: Set(); users  with modify permissions: Set(mikeg); groups with modify permissions: Set()
21/05/27 17:44:39 INFO Utils: Successfully started service 'sparkDriver' on port 44351.
21/05/27 17:44:39 INFO SparkEnv: Registering MapOutputTracker
21/05/27 17:44:39 INFO SparkEnv: Registering BlockManagerMaster
21/05/27 17:44:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/05/27 17:44:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/05/27 17:44:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/05/27 17:44:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f528d073-44e7-4f97-9ffa-976d706340ed
21/05/27 17:44:39 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/05/27 17:44:39 INFO SparkEnv: Registering OutputCommitCoordinator
21/05/27 17:44:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/05/27 17:44:40 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/05/27 17:44:40 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.20:4041
21/05/27 17:44:41 INFO Executor: Starting executor ID driver on host 192.168.1.20
21/05/27 17:44:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35907.
21/05/27 17:44:41 INFO NettyBlockTransferService: Server created on 192.168.1.20:35907
21/05/27 17:44:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/05/27 17:44:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.20, 35907, None)
21/05/27 17:44:41 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.20:35907 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.1.20, 35907, None)
21/05/27 17:44:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.20, 35907, None)
21/05/27 17:44:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.20, 35907, None)
21/05/27 17:44:43 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/mikeg/Documents/databases/TPC-H/TPC-H_Tools_v3.0.0/dbgen/tmpqueries/spark-warehouse/').
21/05/27 17:44:43 INFO SharedState: Warehouse path is 'file:/home/mikeg/Documents/databases/TPC-H/TPC-H_Tools_v3.0.0/dbgen/tmpqueries/spark-warehouse/'.
21/05/27 17:44:46 INFO InMemoryFileIndex: It took 122 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 15 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 6 ms to list leaf files for 1 paths.
21/05/27 17:44:50 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
21/05/27 17:44:51 INFO InMemoryFileIndex: It took 5 ms to list leaf files for 1 paths.
21/05/27 17:44:54 INFO FileSourceStrategy: Pushed Filters: IsNotNull(l_shipdate),IsNotNull(l_discount),IsNotNull(l_quantity),GreaterThanOrEqual(l_shipdate,1994-01-01),LessThan(l_shipdate,1995-01-01),GreaterThanOrEqual(l_discount,0.05),LessThanOrEqual(l_discount,0.07),LessThan(l_quantity,24.0)
21/05/27 17:44:54 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(l_shipdate#100),isnotnull(l_discount#96),isnotnull(l_quantity#94),(l_shipdate#100 >= 8766),(l_shipdate#100 < 9131),(l_discount#96 >= 0.05),(l_discount#96 <= 0.07),(l_quantity#94 < 24.0)
21/05/27 17:44:54 INFO FileSourceStrategy: Output Data Schema: struct<l_quantity: double, l_extendedprice: double, l_discount: double, l_shipdate: date ... 2 more fields>
21/05/27 17:44:57 INFO CodeGenerator: Code generated in 1240.619323 ms
21/05/27 17:44:58 INFO CodeGenerator: Code generated in 84.821718 ms
21/05/27 17:45:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KiB, free 366.0 MiB)
21/05/27 17:45:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 366.0 MiB)
21/05/27 17:45:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.20:35907 (size: 24.0 KiB, free: 366.3 MiB)
21/05/27 17:45:00 INFO SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0
21/05/27 17:45:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
21/05/27 17:45:01 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
21/05/27 17:45:01 INFO DAGScheduler: Registering RDD 3 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 0
21/05/27 17:45:01 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/05/27 17:45:01 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)
21/05/27 17:45:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
21/05/27 17:45:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
21/05/27 17:45:01 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/27 17:45:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 20.6 KiB, free 366.0 MiB)
21/05/27 17:45:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 366.0 MiB)
21/05/27 17:45:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.20:35907 (size: 9.6 KiB, free: 366.3 MiB)
21/05/27 17:45:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383
21/05/27 17:45:01 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
21/05/27 17:45:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 6 tasks resource profile 0
21/05/27 17:45:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.1.20, executor driver, partition 0, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:01 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.1.20, executor driver, partition 1, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:01 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.1.20, executor driver, partition 2, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:01 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (192.168.1.20, executor driver, partition 3, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:01 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
21/05/27 17:45:01 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
21/05/27 17:45:01 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/05/27 17:45:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/05/27 17:45:02 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 402653184-536870912, partition values: [empty row]
21/05/27 17:45:02 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 268435456-402653184, partition values: [empty row]
21/05/27 17:45:02 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 0-134217728, partition values: [empty row]
21/05/27 17:45:02 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 134217728-268435456, partition values: [empty row]
21/05/27 17:45:02 INFO CodeGenerator: Code generated in 18.479257 ms
21/05/27 17:45:02 INFO CodeGenerator: Code generated in 19.838263 ms
21/05/27 17:45:02 INFO CodeGenerator: Code generated in 21.742775 ms
21/05/27 17:45:02 INFO CodeGenerator: Code generated in 22.965265 ms
21/05/27 17:45:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2070 bytes result sent to driver
21/05/27 17:45:06 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2070 bytes result sent to driver
21/05/27 17:45:06 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2027 bytes result sent to driver
21/05/27 17:45:06 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2070 bytes result sent to driver
21/05/27 17:45:06 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (192.168.1.20, executor driver, partition 4, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:06 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (192.168.1.20, executor driver, partition 5, ANY, 4872 bytes) taskResourceAssignments Map()
21/05/27 17:45:06 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
21/05/27 17:45:06 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
21/05/27 17:45:06 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 671088640-759863287, partition values: [empty row]
21/05/27 17:45:06 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 4834 ms on 192.168.1.20 (executor driver) (1/6)
21/05/27 17:45:06 INFO FileScanRDD: Reading File path: hdfs://localhost:9000/user/diplomma/data/data/lineitem.tbl, range: 536870912-671088640, partition values: [empty row]
21/05/27 17:45:06 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4844 ms on 192.168.1.20 (executor driver) (2/6)
21/05/27 17:45:06 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 4850 ms on 192.168.1.20 (executor driver) (3/6)
21/05/27 17:45:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4870 ms on 192.168.1.20 (executor driver) (4/6)
21/05/27 17:45:07 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2027 bytes result sent to driver
21/05/27 17:45:07 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 1532 ms on 192.168.1.20 (executor driver) (5/6)
21/05/27 17:45:08 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2027 bytes result sent to driver
21/05/27 17:45:08 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 2128 ms on 192.168.1.20 (executor driver) (6/6)
21/05/27 17:45:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/05/27 17:45:08 INFO DAGScheduler: ShuffleMapStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 7.151 s
21/05/27 17:45:08 INFO DAGScheduler: looking for newly runnable stages
21/05/27 17:45:08 INFO DAGScheduler: running: Set()
21/05/27 17:45:08 INFO DAGScheduler: waiting: Set(ResultStage 1)
21/05/27 17:45:08 INFO DAGScheduler: failed: Set()
21/05/27 17:45:08 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
21/05/27 17:45:08 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.2 KiB, free 366.0 MiB)
21/05/27 17:45:08 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 366.0 MiB)
21/05/27 17:45:08 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.20:35907 (size: 5.5 KiB, free: 366.3 MiB)
21/05/27 17:45:08 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1383
21/05/27 17:45:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/05/27 17:45:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
21/05/27 17:45:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 6) (192.168.1.20, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/27 17:45:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 6)
21/05/27 17:45:08 INFO ShuffleBlockFetcherIterator: Getting 6 (360.0 B) non-empty blocks including 6 (360.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/27 17:45:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 12 ms
21/05/27 17:45:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 6). 2673 bytes result sent to driver
21/05/27 17:45:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 6) in 130 ms on 192.168.1.20 (executor driver) (1/1)
21/05/27 17:45:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/05/27 17:45:08 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.144 s
21/05/27 17:45:08 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/27 17:45:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/05/27 17:45:08 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 7.418546 s
21/05/27 17:45:08 INFO CodeGenerator: Code generated in 15.520342 ms
21/05/27 17:45:08 INFO SparkContext: Invoking stop() from shutdown hook
21/05/27 17:45:08 INFO SparkUI: Stopped Spark web UI at http://192.168.1.20:4041
21/05/27 17:45:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/05/27 17:45:08 INFO MemoryStore: MemoryStore cleared
21/05/27 17:45:08 INFO BlockManager: BlockManager stopped
21/05/27 17:45:08 INFO BlockManagerMaster: BlockManagerMaster stopped
21/05/27 17:45:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/05/27 17:45:08 INFO SparkContext: Successfully stopped SparkContext
21/05/27 17:45:08 INFO ShutdownHookManager: Shutdown hook called
21/05/27 17:45:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a531273-86cd-4f62-9791-4b21aed4c74c
21/05/27 17:45:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-917a9286-5f8d-4609-a820-6392d2550f14
21/05/27 17:45:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a531273-86cd-4f62-9791-4b21aed4c74c/pyspark-687d2322-643c-4842-8890-3f5b3fe92a5c
